# Анализ токсичных коментариев с BERT
BERT (Bidirectional Encoder Representations from Transformers) — это языковая модель от Google (2018), как ясно из названия, ее оснонвная цель – кодирование текста (создание эмбеддингов) с сохранением контекста. Ее подвид, toxic-bert, мы будем использовать как feature extractor для классификации токсичных комментариев.

## Задача

Бинарная классификация комментариев из социальных сетей по токсичности.

## Данные

`toxic_comments.csv`  содержит ~160к комментариев и разметку токсичности в столбце toxic.
(Подгружаю с api Яндекса в тетрадке, т.к. файл слишком большой для GitHub)

## Подходы

1. Логистическая регрессия с BERT эмбеддингами в качестве фичей(базовая модель);
2. Полносвязная нейросеть torch на эмбэддингах BERT в качестве фичей;
3. Логистическая регрессия на скоринге Detoxify в качестве фичей.

## Метрика

RP-AUC (она же average precision)

Почему:
- Устойчива к дисбаллансу;
- Отражает качество предсказания положительного класса (важно в задаче анализа комментариев на токсичность.)

## Итоги

Лучше всего показал себя подход с Detoxify (PR-AUC=0.99)
